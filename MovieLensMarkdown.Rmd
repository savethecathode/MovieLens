---
title: "MovieLensMarkdown"
output: pdf_document
author: "Leo PeBenito"
date: "3/9/2020"
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H}  # Fixes table pos opt 'H'
fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=TRUE)
setwd("~/TemplRprojects/MovieLens")
load("~/TemplRprojects/MovieLens/movielensdata.RData") # load data sets: edx, validation, train, test
library(tidyverse)
library(caret)
library(lubridate)
library(knitr)
library(gridExtra)  # arrange figures
```

## Abstract
...we use 10M MovieLens dataset.
...construct algo to predict movie ratings 

## Recommendation System: MovieLens Dataset

The purpose of this exercise is to develop an algorithm that predicts a user $i$'s rating of a given movie $u$.
Recommendation systems contrast to other ML algorithms (ie: ???) because each outcome has a different set of prodictors...

Setup ML terminology:
outcomes: movie ratings are not binary, and not totally continuous, let's say discrete.
loss function: residual mean squared error (RMSE = ${1\over N} \sum_{i=1}^N ({\hat Y}_i - Y_i)^2$)


Exploratory data analysis of the MovieLens 10M data set.
Movie ratings obtained by research from the Lens lab.
Ratings range from 0.5 to 5 stars.


## Exploratory Data Analysis
What is the distribution of movie ratings?
The distribution of movie ratings shows the average rating is 3.5 stars.

Looking at the average moving rating over time shows that the average rating is consistently 3.5 stars.

```{r, echo=FALSE, fig.align='center', out.width='0.95\\linewidth', fig.cap="Bar plot of the number of ratings with a given number of stars divided by the total number of ratings plotted v. rating as the number of stars."}
N  <- length(train_set$rating)
mu <- mean(train_set$rating)
train_set %>% group_by(rating) %>%
  summarize(n = n()/N) %>% 
  ggplot(aes(rating, n)) +
  geom_bar(stat="identity") +
  xlab("Movie rating (no. stars)") +
  ylab("Ave. no. ratings") +
  geom_vline(aes(xintercept=mu), col="red")
```

Very few ratings in 1995, and few ratings for 2009.
Can try to account for this using regularization (but only if it's actually useful)...

Investigage variation in movie ratings 
```{r year, echo=FALSE, fig.align='center', out.width='\\linewidth', fig.cap=""}
p1 <- train_set %>% group_by(year) %>%
  summarize(n=n()) %>%
  ggplot(aes(year, n)) +
  geom_bar(stat="identity") +
  xlab("Year") +
  ylab("Total No. Ratings") +
  scale_y_continuous(labels = function(x) format(x, scientific=TRUE))
  
p2 <- train_set %>% group_by(year) %>%
  summarize(ave=mean(rating)) %>%
  ggplot(aes(year, ave, group=1)) +
  geom_line() +
  ylim(c(2.5,4.5)) +
  xlab("Year") +
  ylab("Ave. no. stars")

grid.arrange(p1, p2, ncol=2)
```

```{r month, echo=FALSE, fig.align='center', out.width='0.95\\linewidth', fig.cap=""}
p1 <- train_set %>% group_by(month) %>%
  summarize(ave=mean(rating), n=n()) %>% 
  ggplot(aes(month, n)) +
  geom_bar(stat="identity") +
  xlab("Month") +
  ylab("No. Ratings")

p2 <- train_set %>% group_by(month) %>%
  summarize(ave=mean(rating)) %>% 
  ggplot(aes(month, ave, group=1)) +
  geom_line() +
  ylim(c(2.5,4.5)) +
  xlab("Month") +
  ylab("Ave. Rating")

grid.arrange(p1, p2, ncol=2)
```

```{r day, echo=FALSE, fig.align='center', out.width='0.95\\linewidth', fig.cap=""}
p1 <- train_set %>% group_by(day) %>%
  summarize(n=n()) %>% 
  ggplot(aes(day, n)) +
  geom_bar(stat="identity") +
  xlab("Day of the Week") +
  ylab("No. Ratings") +
  theme(axis.text.x=element_text(angle=90, hjust=1))

p2 <- train_set %>% group_by(day) %>%
  summarize(ave=mean(rating)) %>% 
  ggplot(aes(day, ave, group=1)) +
  geom_line() +
  ylim(c(2.5,4.5)) +
  xlab("Day of the Week") +
  ylab("Ave. Rating") +
  theme(axis.text.x=element_text(angle=90, hjust=1))

grid.arrange(p1, p2, ncol=2)
```

Clearly the overall average is 3.5 but if we guess 3.5 we will be wrong most of the time because most people either pick 3 or 4.
In general whole star ratings are more common than half-star ratings (fig.1).


```{r, echo=FALSE}
train_set %>% group_by(month, year) %>%
  summarize(avg_rating = mean(rating)) %>%
  ggplot(aes(month, avg_rating, group=year, color=year)) +
  geom_line() +
  scale_color_gradientn(colors=rainbow(5))
```

```{r, echo=FALSE}
train_set %>% group_by(day, year) %>%
  summarize(avg_rating = mean(rating)) %>%
  ggplot(aes(day, avg_rating, group=year, color=year)) +
  geom_line() +
  scale_color_gradientn(colors=rainbow(5))
```


Smooth out this loess estimate...
```{r, echo=FALSE, fig.cap="fit of average rating each week using loess()"}
#train_set %>% filter(year > 1996) %>%
train_set %>%
  mutate(date = round_date(as_datetime(timestamp), unit="week")) %>%
  group_by(date, year) %>%
  summarize(rating=mean(rating)) %>%
  ggplot(aes(date, rating, group=year, color=year)) +
  geom_point() +
  geom_smooth(color="black") +
  scale_color_gradientn(colors=rainbow(5))
```

Number of genres...
```{r, echo=FALSE, fig.align='center', out.width='0.95\\linewidth', fig.cap="Number of genres"}
p1 <- train_set %>% group_by(no_genres) %>%
  summarize(n=n()) %>% 
  ggplot(aes(no_genres, n)) +
  geom_bar(stat="identity") +
  xlab("No. genres") +
  ylab("No. Ratings")

p2 <- train_set %>% group_by(no_genres) %>%
  summarize(ave=mean(rating)) %>% 
  ggplot(aes(no_genres, ave, group=1)) +
  geom_line() +
  ylim(c(2.5,4.5)) +
  xlab("No. genres") +
  ylab("Ave. Rating")

grid.arrange(p1, p2, ncol=2)
```

Genre...
```{r, echo=FALSE, fig.align='center', out.width='0.95\\linewidth', fig.cap="Number of genres"}
p1 <- train_set %>% group_by(genre) %>%
  summarize(n=n()) %>% 
  ggplot(aes(genre, n)) +
  geom_bar(stat="identity") +
  xlab("Genre") +
  ylab("No. Ratings") +
  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1))

p2 <- train_set %>% group_by(genre) %>%
  summarize(ave=mean(rating)) %>% 
  ggplot(aes(genre, ave, group=1)) +
  geom_line() +
  ylim(c(2.5,4.5)) +
  xlab("Genre") +
  ylab("Ave. Rating") +
  theme(axis.text.x=element_text(angle=90, vjust=0.5, hjust=1))

grid.arrange(p1, p2, ncol=2)
```

Model

$$ Y_{u,i} = \mu + b_i + b_u + f(time) + g(genre) + p_u*q_i + \epsilon_{u,i}$$

## PCA
Convert data to a matrix with users for rows and movies for columns.

$$ p_u*q_i = \sum_{i=1}^N p_u\cdot q_i$$ ???

## Regularization
Regularization penalizes large estimages that come from a relatively small number of observations.
Minimize the equation 
$${1\over N}\sum_{u,i} (y_{u,i} - \mu - b_i)^2 + \lambda\sum_i b_i^2$$
to find the $b$'s
$${\hat b}_i(\lambda)={1\over \lambda + n_i}\sum_{u=1}^{n_i} (Y_{u,i}-{\hat\mu})$$   
``$\lambda$ is a tuning parameter so we can use cross validation to choose it.''
``We should be using full cross-validation on just the training set, without using the test set until the final assessment. ''

```{r}
lambdas <- seq(0, 10, 0.1)
start_time <- Sys.time()
rmses <- sapply(lambdas, function(lambda){
  
  mu <- mean(train_set$rating)
  
  b_i <- train_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+lambda))
  
  predicted_ratings <- test_set %>%
    left_join(b_i, by="movieId") %>%
    mutate(pred = mu + b_i) %>%
    .$pred
  
  return(RMSE(predicted_ratings, test_set$rating))
})
end_time <- Sys.time()
end_time - start_time   # can this be faster?

qplot(lambdas, rmses)

lambda <- lambdas[which.min(rmses)]
```

For the movie effect and user user effect.
$${1\over N}\sum_{u,i}(y_{u,i}-\mu-b_i-b_u)^2 + \lambda(\sum_i b_i^2 + \sum_u b_u^2)$$

```{r, echo=FALSE}
lambdas <- seq(0, 10, 0.1)
start_time <- Sys.time()
rmses <- sapply(lambdas, function(lambda){

  mu <- mean(train_set$rating)
  
  b_i <- train_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+lambda))
  
  b_u <- train_set %>%
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))
  
  predicted_ratings <- test_set %>%
    left_join(b_i, by="movieId") %>%
    left_join(b_u, by="userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    .$pred
  
  return(RMSE(predicted_ratings, test_set$rating))
})
end_time <- Sys.time()
end_time - start_time   # can this be faster?

qplot(lambdas, rmses)

lambda <- lambdas[which.min(rmses)]
```

```{r, echo=FALSE, results='asis', fig.pos='H'}
kable(rmse_results, caption="RMSE Results")
```